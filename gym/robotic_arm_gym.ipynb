{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym import utils\n",
    "from gym.envs.mujoco import MujocoEnv\n",
    "from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDiscreteManipulatorEnv(MujocoEnv, utils.EzPickle):\n",
    "    \"\"\"\n",
    "    Custom Gym Environment for a 3-DOF robotic arm with discrete action space\n",
    "    and an additional action for pushing a button with the end-effector.\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        \"render_modes\": [\n",
    "            \"human\",\n",
    "            \"rgb_array\",\n",
    "            \"depth_array\",\n",
    "        ],\n",
    "        \"render_fps\": 50,\n",
    "    }\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        utils.EzPickle.__init__(self, **kwargs)\n",
    "        \n",
    "        # Observation space: 19-dimensional continuous space\n",
    "        observation_space = Box(low=-np.inf, high=np.inf, shape=(19,), dtype=np.float64)\n",
    "\n",
    "        # Discrete action space: 54 possible actions (3^3 for torques, plus 1 for the button)\n",
    "        action_space = Discrete(54)\n",
    "        \n",
    "        # Initial torques (in the range [-1, 1]) for the three joints\n",
    "        self.torques = np.zeros(3)\n",
    "\n",
    "        # Track the button state (0: off, 1: on) and end-effector push state\n",
    "        self.button_state = 0\n",
    "        self.end_effector_pushed = 0  # Tracks if the end-effector has pushed the button\n",
    "\n",
    "        MujocoEnv.__init__(\n",
    "            self, \"robotic_arm.xml\", 2, observation_space=observation_space, action_space=action_space, **kwargs\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        # Reset the end-effector push state before every step\n",
    "        self.end_effector_pushed = 0\n",
    "        \n",
    "        # Action mapping for torque changes on the joints\n",
    "        action_map = [\n",
    "            (-0.1, -0.1, -0.1), (-0.1, -0.1, 0), (-0.1, -0.1, 0.1),\n",
    "            (-0.1, 0, -0.1), (-0.1, 0, 0), (-0.1, 0, 0.1),\n",
    "            (-0.1, 0.1, -0.1), (-0.1, 0.1, 0), (-0.1, 0.1, 0.1),\n",
    "            (0, -0.1, -0.1), (0, -0.1, 0), (0, -0.1, 0.1),\n",
    "            (0, 0, -0.1), (0, 0, 0), (0, 0, 0.1),\n",
    "            (0, 0.1, -0.1), (0, 0.1, 0), (0, 0.1, 0.1),\n",
    "            (0.1, -0.1, -0.1), (0.1, -0.1, 0), (0.1, -0.1, 0.1),\n",
    "            (0.1, 0, -0.1), (0.1, 0, 0), (0.1, 0, 0.1),\n",
    "            (0.1, 0.1, -0.1), (0.1, 0.1, 0), (0.1, 0.1, 0.1)\n",
    "        ]\n",
    "        \n",
    "        # If action is < 27, it means itâ€™s a torque action\n",
    "        if action < 27:\n",
    "            torque_delta = np.array(action_map[action])\n",
    "            self.torques = np.clip(self.torques + torque_delta, -1.0, 1.0)\n",
    "        else:\n",
    "            # Action 27-53 represents the torque + button operation (action-27)\n",
    "            torque_delta = np.array(action_map[action - 27])\n",
    "            self.torques = np.clip(self.torques + torque_delta, -1.0, 1.0)\n",
    "            self._attempt_push_button()  # Simulate the button push action\n",
    "\n",
    "        # Perform simulation with the updated torques\n",
    "        self.do_simulation(self.torques, self.frame_skip)\n",
    "        \n",
    "        # Observation\n",
    "        ob = self._get_obs()\n",
    "        \n",
    "        # Calculate the reward based on the current state\n",
    "        reward, done = self._calculate_reward()\n",
    "\n",
    "        # Return observations, reward, done flag, and additional info\n",
    "        info = {\"button_state\": self.button_state}\n",
    "        return ob, reward, done, info\n",
    "\n",
    "    def _attempt_push_button(self):\n",
    "        \"\"\"\n",
    "        Handles the logic for the button push and updates the end-effector state.\n",
    "        \"\"\"\n",
    "        end_effector_pos = self.get_body_com(\"link_3\")\n",
    "        target_pos = self.get_body_com(\"target\")\n",
    "        relative_distance = np.linalg.norm(end_effector_pos - target_pos)\n",
    "\n",
    "        # If the end-effector is close enough, mark it as pushed\n",
    "        if relative_distance < 0.05:\n",
    "            self.end_effector_pushed = 1  # End-effector is in the \"pushed\" state\n",
    "            self.button_state = 1  # Button is switched to \"on\"\n",
    "        else:\n",
    "            self.button_state = 0  # Invalid push, button remains \"off\"\n",
    "\n",
    "    def _calculate_reward(self):\n",
    "        \"\"\"\n",
    "        Computes the reward based on the current state of the environment.\n",
    "        \"\"\"\n",
    "        end_effector_pos = self.get_body_com(\"link_3\")\n",
    "        target_pos = self.get_body_com(\"target\")\n",
    "        relative_distance = np.linalg.norm(end_effector_pos - target_pos)\n",
    "\n",
    "        reward = 0\n",
    "        \n",
    "        # 1. Dense negative reward based on the relative distance\n",
    "        reward += -0.01 * relative_distance\n",
    "        \n",
    "        # 2. Positive reward of 1 when the end-effector is close enough to the target\n",
    "        if relative_distance < 0.05:\n",
    "            reward += 1\n",
    "        \n",
    "        # 3. Penalty for invalid button press\n",
    "        if self.end_effector_pushed == 1 and relative_distance >= 0.05:\n",
    "            reward -= 1  # Penalty for invalid push action\n",
    "\n",
    "        # 4. Large positive reward when the button is successfully pushed\n",
    "        if self.button_state == 1:\n",
    "            reward += 100\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        return reward, done\n",
    "\n",
    "    def reset_model(self):\n",
    "        \"\"\"\n",
    "        Reset the environment to its initial state.\n",
    "        \"\"\"\n",
    "        # Randomly initialize joint positions and velocities\n",
    "        qpos = self.init_qpos + self.np_random.uniform(low=-0.1, high=0.1, size=self.model.nq)\n",
    "        qvel = self.init_qvel + self.np_random.uniform(low=-0.005, high=0.005, size=self.model.nv)\n",
    "        self.set_state(qpos, qvel)\n",
    "\n",
    "        # Reset torques, button state, and end-effector push state\n",
    "        self.torques = np.zeros(3)\n",
    "        self.button_state = 0\n",
    "        self.end_effector_pushed = 0\n",
    "\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"\n",
    "        Returns the current observation of the environment.\n",
    "        Includes the end-effector push state.\n",
    "        \"\"\"\n",
    "        # Cosine and sine of the angles of the three joints\n",
    "        theta = self.data.qpos.flat[:3]\n",
    "        \n",
    "        # End-effector position (x, y, z)\n",
    "        end_effector_pos = self.get_body_com(\"link_3\")\n",
    "        \n",
    "        # Target position (x, y, z)\n",
    "        target_pos = self.get_body_com(\"target\")\n",
    "        \n",
    "        # Difference between end-effector and target positions\n",
    "        position_diff = end_effector_pos - target_pos\n",
    "        \n",
    "        # Angular velocities of the 3 joints\n",
    "        angular_velocities = self.data.qvel.flat[:3]\n",
    "\n",
    "        # Concatenate all the observation elements\n",
    "        observation = np.concatenate([\n",
    "            np.cos(theta),              # Cosine of joint angles\n",
    "            np.sin(theta),              # Sine of joint angles\n",
    "            target_pos,                 # Target position (x, y, z)\n",
    "            end_effector_pos,           # End-effector position (x, y, z)\n",
    "            angular_velocities,         # Angular velocities\n",
    "            position_diff,              # Difference in positions (x, y, z)\n",
    "            [self.end_effector_pushed]  # End-effector push state (0 or 1)\n",
    "        ])\n",
    "        \n",
    "        return observation\n",
    "\n",
    "    def viewer_setup(self):\n",
    "        \"\"\"\n",
    "        Sets up the viewer for rendering.\n",
    "        \"\"\"\n",
    "        assert self.viewer is not None\n",
    "        self.viewer.cam.trackbodyid = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me5418-mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
